
<!-- TOC -->

- [功能描述](#%e5%8a%9f%e8%83%bd%e6%8f%8f%e8%bf%b0)
	- [功能](#%e5%8a%9f%e8%83%bd)
	- [图文积压定时警报](#%e5%9b%be%e6%96%87%e7%a7%af%e5%8e%8b%e5%ae%9a%e6%97%b6%e8%ad%a6%e6%8a%a5)
	- [host白名单](#host%e7%99%bd%e5%90%8d%e5%8d%95)
	- [业务描述](#%e4%b8%9a%e5%8a%a1%e6%8f%8f%e8%bf%b0)
	- [云剪辑](#%e4%ba%91%e5%89%aa%e8%be%91)
	- [评论补充弹幕](#%e8%af%84%e8%ae%ba%e8%a1%a5%e5%85%85%e5%bc%b9%e5%b9%95)
	- [用户封禁](#%e7%94%a8%e6%88%b7%e5%b0%81%e7%a6%81)
	- [弹幕屏蔽词](#%e5%bc%b9%e5%b9%95%e5%b1%8f%e8%94%bd%e8%af%8d)
	- [用户视频播放量定时更新](#%e7%94%a8%e6%88%b7%e8%a7%86%e9%a2%91%e6%92%ad%e6%94%be%e9%87%8f%e5%ae%9a%e6%97%b6%e6%9b%b4%e6%96%b0)
	- [发送通知](#%e5%8f%91%e9%80%81%e9%80%9a%e7%9f%a5)
		- [single通知 对notice topic代码的研究](#single%e9%80%9a%e7%9f%a5-%e5%af%b9notice-topic%e4%bb%a3%e7%a0%81%e7%9a%84%e7%a0%94%e7%a9%b6)
		- [multi 开协程发送通知](#multi-%e5%bc%80%e5%8d%8f%e7%a8%8b%e5%8f%91%e9%80%81%e9%80%9a%e7%9f%a5)
		- [广播模式 databus代码](#%e5%b9%bf%e6%92%ad%e6%a8%a1%e5%bc%8f-databus%e4%bb%a3%e7%a0%81)
- [源码研读](#%e6%ba%90%e7%a0%81%e7%a0%94%e8%af%bb)
	- [视频源码](#%e8%a7%86%e9%a2%91%e6%ba%90%e7%a0%81)
		- [稿件表每个字段的设计意义](#%e7%a8%bf%e4%bb%b6%e8%a1%a8%e6%af%8f%e4%b8%aa%e5%ad%97%e6%ae%b5%e7%9a%84%e8%ae%be%e8%ae%a1%e6%84%8f%e4%b9%89)
		- [过滤的实现](#%e8%bf%87%e6%bb%a4%e7%9a%84%e5%ae%9e%e7%8e%b0)
		- [svid的生成原因](#svid%e7%9a%84%e7%94%9f%e6%88%90%e5%8e%9f%e5%9b%a0)
		- [转码的实现](#%e8%bd%ac%e7%a0%81%e7%9a%84%e5%ae%9e%e7%8e%b0)
		- [转码url是如何做的](#%e8%bd%ac%e7%a0%81url%e6%98%af%e5%a6%82%e4%bd%95%e5%81%9a%e7%9a%84)
- [总结经验](#%e6%80%bb%e7%bb%93%e7%bb%8f%e9%aa%8c)
	- [XSS攻击](#xss%e6%94%bb%e5%87%bb)
	- [CSRF](#csrf)
	- [UAT和UT](#uat%e5%92%8cut)
		- [UAT(验收测试，User Acceptance Test)](#uat%e9%aa%8c%e6%94%b6%e6%b5%8b%e8%af%95user-acceptance-test)
		- [UT(单元测试，Unit Test)](#ut%e5%8d%95%e5%85%83%e6%b5%8b%e8%af%95unit-test)
		- [IT（集成测试，Integration Test）](#it%e9%9b%86%e6%88%90%e6%b5%8b%e8%af%95integration-test)
		- [ST（系统测试，System Test）](#st%e7%b3%bb%e7%bb%9f%e6%b5%8b%e8%af%95system-test)
	- [Mock](#mock)
	- [定义](#%e5%ae%9a%e4%b9%89)
		- [好处](#%e5%a5%bd%e5%a4%84)
	- [gorm](#gorm)
- [传值还是传地址](#%e4%bc%a0%e5%80%bc%e8%bf%98%e6%98%af%e4%bc%a0%e5%9c%b0%e5%9d%80)
- [canal](#canal)
	- [原理](#%e5%8e%9f%e7%90%86)
	- [应用](#%e5%ba%94%e7%94%a8)
- [restful 和 rpc 区别](#restful-%e5%92%8c-rpc-%e5%8c%ba%e5%88%ab)
	- [用途](#%e7%94%a8%e9%80%94)
- [grpc](#grpc)
	- [Request](#request)
	- [Response](#response)
	- [Protobuf](#protobuf)
- [http1 和 http 2](#http1-%e5%92%8c-http-2)
	- [http1.x](#http1x)
	- [http2](#http2)
		- [Frame组成](#frame%e7%bb%84%e6%88%90)
	- [stream特性](#stream%e7%89%b9%e6%80%a7)
	- [HPACK(头部简化)](#hpack%e5%a4%b4%e9%83%a8%e7%ae%80%e5%8c%96)
	- [FlowControl](#flowcontrol)

<!-- /TOC -->

# 功能描述
尚学堂golang实战项目,来自抖音的资深工程师手把手教你从零搭建小视频百万连接高性能后端

## 功能

## 图文积压定时警报


bug  uat和local一起抢占databus
     redis.do的reply 用redis.bool来判断,结果返回的reply的意义是count;当count为0的时候会报会退出,导致失败


```go

func (d *Dao) GetEarliestTaskTimeDb(ctx context.Context, workflowId int16) (t *time.Time, err error) {
	sqlStr := fmt.Sprintf(_sqlTaskEarliestTime)
	t = new(time.Time)
	row := d.db.QueryRow(ctx, sqlStr, workflowId)
	err = row.Scan(t)
	if err == sql.ErrNoRows {
		return t, nil
	}
	return
}

func (d *Dao) GetTaskCountDb(ctx context.Context, workFlowId int16) (count int, err error) {
	row := d.db.QueryRow(ctx, _sqlTaskStackCount, workFlowId)
	err = row.Scan(&count)
	if err != nil {
		log.Errorc(ctx, "GetTaskCountDb Failed ,error:%v", err)
		return
	}
	return
}

func (d *Dao) SetTaskCountRedis(ctx context.Context, workflowId int16, count int) (int, error) {
	key := fmt.Sprintf(TaskStackCount, workflowId)
	conn := d.redis.Get(ctx)
	defer conn.Close()

	reply, err := conn.Do("SET", key, count)

	if reply != "OK" || err != nil {
		log.Errorw(ctx, "SetTaskCountRedis error", err)
		return -1, err
	}
	_, err = conn.Do("EXPIRE", key, 86400)
	if err != nil {
		log.Errorw(ctx, "SetTaskCountRedis,set expire error:", err)
		return -1, err
	}
	count, err = redis.Int(conn.Do("GET", key))
	if err != nil {
		log.Errorc(ctx, "get TaskStackCount error:%#v", err)
	}
	return count, err
}

func (d *Dao) GetTaskStackCountRedis(ctx context.Context, workflowId int16) (count int, err error) {
	key := fmt.Sprintf(TaskStackCount, workflowId)
	conn := d.redis.Get(ctx)
	defer conn.Close()

	//TODO失效之后去 重置一个数据?
	count, err = redis.Int(conn.Do("GET", key))
	if err != nil {
		log.Errorc(ctx, "Redis Get TaskStackCount Failed ,error:%v", err)
		return
	}
	return
}

func (d *Dao) TaskStackCountIncre(ctx context.Context, workFlow int16) (count int, err error) {
	key := fmt.Sprintf(TaskStackCount, workFlow)
	conn := d.redis.Get(ctx)
	defer conn.Close()

	reply, err := conn.Do("INCR", key)
	if count, err = redis.Int(reply, err); err != nil {
		log.Errorw(ctx, "TaskStackCountIncre", "error", err)
		return
	}
	_, err = conn.Do("EXPIRE", key, 86400)
	if err != nil {
		log.Errorw(ctx, "TaskStackCountIncre,set expire error:", err)
	}

	log.Info("count:%d,workFlow:%d", count, workFlow)
	return count, err
}

func (d *Dao) TaskStackCountDecr(ctx context.Context, workFlow int16, decCount int) (count int, err error) {
	key := fmt.Sprintf(TaskStackCount, workFlow)
	conn := d.redis.Get(ctx)
	defer conn.Close()

	if count, err = redis.Int(conn.Do("DECRBY", key, decCount)); err != nil {
		log.Errorw(ctx, "event", "TaskStackCountDecr", "error", err, "count", count)
	}
	_, err = conn.Do("EXPIRE", key, 86400)
	if err != nil {
		log.Errorw(ctx, "TaskStackCountDecr,set expire error:", err)
	}

	log.Info("count:%d,workFlow:%d", count, workFlow)
	return count, err
}

```
## host白名单
建表
```sql
CREATE TABLE `white_host` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '唯一主键',
  `host` varchar(255) NOT NULL DEFAULT '' COMMENT '白名单域名',
  `description` varchar(1000) NOT NULL DEFAULT '' COMMENT '域名描述',
  `status` tinyint(4) unsigned NOT NULL DEFAULT '0' COMMENT '域名的状态',
  `ctime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '插入时间',
  `mtime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`),
  KEY `ix_mtime` (`mtime`),
  KEY `ix_host` (`host`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT '域名白名单记录表'

```

其中 mtime有两个属性，分别是CURRENT_TIMESTAMP 和ON UPDATE CURRENT_TIMESTAMP两种，使用情况分别如下：

1. CURRENT_TIMESTAMP 

当要向数据库执行insert操作时，如果有个timestamp字段属性设为 CURRENT_TIMESTAMP，则无论这个字段有没有set值都插入当前系统时间


2. ON UPDATE CURRENT_TIMESTAMP
当执行update操作是，并且字段有ON UPDATE CURRENT_TIMESTAMP属性。则字段无论值有没有变化，它的值也会跟着更新为当前UPDATE操作时的时间。

AUTO_INCREMENT=1000是从1000开始增长

```sql
ALTER TABLE white_host ADD UNIQUE (host);  
``` 
host修改为unique,白名单数据没必要重复



## 业务描述
bbq  cms admin  负责 增加 删除 获取所有host;
增加和删除的时候要删除rediskey;
获取的时候先获取redis,获取不到就数据库,然后更新库

bbq app interface  调用admin  返回给前端host列表
## 云剪辑
长视频剪辑,存标志位,然后存短视频,视频在云端剪好,主站返回svid等信息
## 评论补充弹幕

## 用户封禁

## 弹幕屏蔽词

## 用户视频播放量定时更新

## 发送通知

cms-admin-notice
notice-service 
user-service

单播的时候同步发送
多播的时候开一个协程
广播的时候,把要广播的信息发送到databus上,交给一个consumer来运行

广播,单播,多播通知:
noticebase的信息有:
点赞的时候会发送通知
notice 部分  发送通知后,


redis记录未读通知
### single通知 对notice topic代码的研究


### multi 开协程发送通知

```go
func (s *Service) NoticeMultiUser(c context.Context, req *api.NoticeMultiUserReq) (empty *empty.Empty, err error) {
	midList := req.MidList

	midChan := s.midChanProducer(midList)

	//开一百个notice协程
	for i := 0; i < 100; i++ {
		err = s.midChanConsumer(midChan, req.Text, req.JumpUrl)
		//TODO 有error可以回收吗?
		if err != nil {
			log.Error("ConcurrentNoticeMultiUser Failed error:%#v", err)
			return
		}
	}
	return
}

//开一个协程把mids放入管道
func (s *Service) midChanProducer(mids []int64) (midChan chan int64) {
	midChan = make(chan int64, 100)
	go func() {
		defer close(midChan)
		for _, v := range mids {
			midChan <- v
		}
	}()
	return
}

//开一个协程消费管道中的mid,发送notice给user
//TODO 要不要context
func (s *Service) midChanConsumer(midChan <-chan int64, text string, jumpUrl string) (err error) {
	go func() {
		for mid := range midChan {
			//fmt.Printf("%d 消费了 %d", flag, mid)
			noticeBase := &notice.NoticeBase{
				Text:       text,
				Mid:        mid,
				NoticeType: notice.NoticeTypeSysMsg,
				BizType:    notice.NoticeBizTypeSysMsg,
				JumpUrl:    jumpUrl,
			}
			ctx := context.Background()
			err = s.dao.CreateSingleNotice(ctx, noticeBase)
			if err != nil {
				log.Errorw(ctx, "event", "ConcurrentNoticeMultiUser Failed", "error", err)
				return
			}
		}
	}()
	return
}
```
### 广播模式 databus代码



# 源码研读
## 视频源码
service 初始化的时候拿到host,把host经过hash操作后,存储到redis,保证每台主机的dao是唯一的不冲突的

稿件表的设计:

for循环监听,message chan;databus订阅主站稿件变动消息,对消息进行查封,拆成newVideo和oldVideo,和action和table

如果是update,判断是否是删除动态,如果是删除动态就同步把自己的视频展示等级设为不可见;还有一种可能是insert,这两种情况都要通过过滤(过滤规则要加载,有tid过滤,up主过滤,视频属性过滤版权最大最小时长比特率主题);过滤完之后

生成svid;由时间戳mid 等构成

创建一个topicClient  现在还不知道是干嘛用的.

把稿件传递给生产流程,通过稿件里面的dynamic(稿件的表设计为什么这样),提取tags,然后稿件信息传给转码的producerClient(可以画图的结构关系client)

在grpc调用的BVCXCodeCommit中,主要做三件事:生成video记录到数据表,提交转码请求(发送一个hhtp请求,包含svid和cid给配置好的请求地址);就可以对视频进行转码,然后返回结果是视频转码,写回稿件表



### 稿件表每个字段的设计意义

### 过滤的实现

### svid的生成原因

### 转码的实现

### 转码url是如何做的



# 总结经验
## XSS攻击  

人们经常将跨站脚本攻击（Cross Site Scripting）缩写为CSS，但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为XSS。

XSS攻击通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。这些恶意网页程序通常是JavaScript，
  
详情博客:
https://blog.csdn.net/qq_36119192/article/details/82469035
## CSRF

用户在未登出A网站的前提下,cookie保留,登陆了恶意网站B,B网站利用还未失效的cookie冒充用户访问A网站.

解决办法:
cookie加密

详情博客:
https://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html

## UAT和UT
### UAT(验收测试，User Acceptance Test)
验收测试是向未来的用户表明系统能够像预定要求那样工作。

经集成测试后，已经按照设计把所有的模块组装成一个完整的软件系统，接口错误也已经基本排除了，接着就应该进一步验证软件的有效性，这就是验收测试的任务，即软件的功能和性能如同用户所合理期待的那样。


### UT(单元测试，Unit Test)
单元测试任务包括：

模块接口测试；
模块局部数据结构测试；
模块边界条件测试；
模块中所有独立执行通路测试；
模块的各条错误处理通路测试。

### IT（集成测试，Integration Test）
也称系统集成测试（System Integration Test）或结合测试。
集成测试阶段是以黑盒法为主，在自底向上集成的早期，白盒法测试占一定的比例，随着集成测试的不断深入，这种比例在测试过程中将越来越少，渐渐地，黑盒法测试占据主导地位。

### ST（系统测试，System Test）
从技术角度看，系统测试是整个测试阶段的最后一步，所有的开发和测试在这一点上集中表现为生成一个具有一定功能的软件系统。
该阶段主要对系统的准确性及完整性等方面进行测试。

主要进行：
功能确认测试、运行测试、强度测试、恢复测试、安全性测试等。

系统测试的测试人员由测试组成员（或质量保证人员）或测试组成员与用户共同测试。在整个系统开发完成，即将交付用户使用前进行。在这一阶段，完全采用黑盒法对整个系统进行测试。

## Mock
https://juejin.im/post/5bd82d796fb9a05d25682a66
## 定义
按照事先规定的接口规范,返回虚拟的数据
### 好处
当使用mock之后，各团队之间可以不需要再互相等待对方的进度，只需要约定好相互之间的数据规范（文档），即可使用mock构建一个可用的接口，然后尽快的进行开发和调试以及自测，提升开发进度的的同时，也将发现缺陷的时间点大大提前。

复现某些接口返回值

提前开始单元测试

## gorm  
废弃gorm,反直觉而且有性能损耗

#  传值还是传地址

go只有值传递,  
传指针则是复制一个指针,可以操作传入参数指向的内存  
传值则是拷贝一份值   
传切片也分传值和传地址:
```go
package main

import (
    "fmt"
)

func main() {
    array := [5]int{0, 1, 2, 3, 4}
    slice := array[:]
    fmt.Println(slice)
    fmt.Printf("slice in main1 %p \n", &slice)
    appendTest(slice)
    fmt.Printf("slice in main2 %p \n", &slice)
    fmt.Println(slice)
    fmt.Println("=============")
    fmt.Println(slice)
    fmt.Printf("slice in main1 %p \n", &slice)
    appendTestRef(&slice)
    fmt.Printf("slice in main2 %p \n", &slice)
    fmt.Println(slice)
}

func appendTest(slice []int) {
    fmt.Printf("slice appendTest1 %p \n", slice)
    slice = append(slice, 5)
    fmt.Println(slice)
    fmt.Printf("slice appendTest2 %p \n", slice)
}

func appendTestRef(slice *[]int) {
    fmt.Printf("slice appendTestRef1 %p \n", slice)
    *slice = append(*slice, 5)
    fmt.Println(slice)
    fmt.Printf("slice appendTestRef2 %p \n", slice)
}
```
```
输出
    [0 1 2 3 4]
    slice in main1 0xc082008520 
    slice appendTest1 0xc08200be90 
    [0 1 2 3 4 5]
    slice appendTest2 0xc08200e1e0 
    slice in main2 0xc082008520 
    [0 1 2 3 4]
    =============
    [0 1 2 3 4]
    slice in main1 0xc082008520 
    slice appendTestRef1 0xc082008520 
    &[0 1 2 3 4 5]
    slice appendTestRef2 0xc082008520 
    slice in main2 0xc082008520 
    [0 1 2 3 4 5]
```

# canal
canal是纯Java开发的，基于数据库增量日志解析，提供增量数据订阅&消费，目前主要支持了mysql。

## 原理

1.      canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议

2.      mysql master收到dump请求，开始推送binary log给slave(也就是canal)

3.      canal解析binary log对象(原始为byte流)

## 应用
canal监听多个表的binlog,解析完成之后,送到kafka的生产者组group-P,topic是cmsTask

再由kafka的对应消费者组group-C,topic也是cmsTask来消费



# restful 和 rpc 区别

RESTful(Representational State Transfer 具象状态传输)是一种设计风格

1. REST 是面向资源的,对资源的操作与它无关，操作是通过 HTTP动词来体现，所以REST 通过 URI 暴露资源时，会强调不要在 URI 中出现动词。
```
GET /rest/api/getDogs --> GET /rest/api/dogs 获取所有小狗狗 
GET /rest/api/addDogs --> POST /rest/api/dogs 添加一个小狗狗 
GET /rest/api/editDogs/:dog_id --> PUT /rest/api/dogs/:dog_id 修改一个小狗狗 
GET /rest/api/deleteDogs/:dog_id --> DELETE /rest/api/dogs/:dog_id 删除一个小狗狗
```
2. 每一个URI代表1种资源；
3. 客户端使用GET、POST、PUT、DELETE4个表示操作方式的动词对服务端资源进行操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；
4. 通过操作资源的表现形式来操作资源；
5. 资源的表现形式是XML或者HTML；
6. 客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。
 
RPC  
简介:  
使用 RPC 样式架构构建的基于 SOAP 的 Web 服务成为实现 SOA 最常用的方法。RPC 样式的 Web 服务客户端将一个装满数据的信封（包括方法和参数信息）通过 HTTP 发送到服务器。服务器打开信封并使用传入参数执行指定的方法。方法的结果打包到一个信封并作为响应发回客户端。客户端收到响应并打开信封。每个对象都有自己独特的方法以及仅公开一个 URI 的 RPC 样式 Web 服务，URI 表示单个端点。它忽略 HTTP 的大部分特性且仅支持 POST 方法。
## 用途

RESTful API：主要用在为第三方提供调用自家系统的一种途径。(客户端)

RPC：主要用在自家系统之间的互相调用，即实现系统的分布式。(微服务之间的调用)

gRPC可以方便地支持流式通信

#  grpc
gRPC 是 Google 基于 HTTP/2 以及 protobuf 的

gRPC可以通过protobuf来定义接口，从而可以有更加严格的接口约束条件(约束更强)

protobuf可以将数据序列化为二进制编码，这会大幅减少需要传输的数据量，从而大幅提高性能。(性能更高)

gRPC 通常有四种模式，unary，client streaming，server streaming 以及 bidirectional streaming，对于底层 HTTP/2 来说，它们都是 stream，并且仍然是一套 request + response 模型。


## Request
gRPC 的 request 通常包含 Request-Headers, 0 或者多个 Length-Prefixed-Message 以及 EOS。
Request-Headers 直接使用的 HTTP/2 headers，在 HEADERS 和 CONTINUATION frame 里面派发。定义的 header 主要有 Call-Definition 以及 Custom-Metadata。Call-Definition 里面包括 Method（其实就是用的 HTTP/2 的 POST），Content-Type 等。而 Custom-Metadata 则是应用层自定义的任意 key-value，key 不建议使用 grpc- 开头，因为这是为 gRPC 后续自己保留的。

Length-Prefixed-Message 主要在 DATA frame 里面派发，它有一个 Compressed flag 用来表示改 message 是否压缩，如果为 1，表示该 message 采用了压缩，而压缩算啊定义在 header 里面的 Message-Encoding 里面。然后后面跟着四字节的 message length 以及实际的 message。

EOS（end-of-stream） 会在最后的 DATA frame 里面带上了 END_STREAM 这个 flag。用来表示 stream 不会在发送任何数据，可以关闭了。


## Response
Response 主要包含 Response-Headers，0 或者多个 Length-Prefixed-Message 以及 Trailers。如果遇到了错误，也可以直接返回 Trailers-Only。
Response-Headers 主要包括 HTTP-Status，Content-Type 以及 Custom-Metadata 等。Trailers-Only 也有 HTTP-Status ，Content-Type 和 Trailers。Trailers 包括了 Status 以及 0 或者多个 Custom-Metadata。

HTTP-Status 就是我们通常的 HTTP 200，301，400 这些，很通用就不再解释。Status 也就是 gRPC 的 status， 而 Status-Message 则是  gRPC 的 message。Status-Message 采用了 Percent-Encoded 的编码方式，具体参考这里。

如果在最后收到的 HEADERS frame 里面，带上了 Trailers，并且有 END_STREAM 这个 flag，那么就意味着 response 的 EOS。


## Protobuf
gRPC 的 service 接口是基于 protobuf 定义的，我们可以非常方便的将 service 与 HTTP/2 关联起来。

Path : /Service-Name/{method name}
Service-Name : ?( {proto package name} "." ) {service name}
Message-Type : {fully qualified proto message name}
Content-Type : "application/grpc+proto"



# http1  和 http 2

## http1.x
HTTP/1.x 协议是一个文本协议，可读性非常好，但其实并不高效

交互模式，一个连接每次只能一问一答，也就是client 发送了 request 之后，必须等到 response，才能继续发送下一次请求。如果需要同时进行大量的交互，client 需要跟 server 建立多条连接，但连接的建立也是有开销的，所以为了性能，通常这些连接都是**长连接一直保活**的，虽然对于 server 来说同时处理百万连接也没啥太大的挑战，但终归效率不高。
## http2
HTTP/2 是一个二进制协议，这也就意味着它的可读性几乎为 0,但可以解析

Stream： 一个双向流，一条连接可以有多个 streams。  
Message： 也就是逻辑上面的 request，response。  
Frame:：数据传输的最小单位。每个 Frame 都属于一个特定的 stream 或者整个连接。一个 message 可能有多个 frame 组成。  

### Frame组成
```
+-----------------------------------------------+
|                 Length (24)                   |
+---------------+---------------+---------------+
|   Type (8)    |   Flags (8)   |
+-+-------------+---------------+-------------------------------+
|R|                 Stream Identifier (31)                      |
+=+=============================================================+
|                   Frame Payload (0...)                      ...
+---------------------------------------------------------------+
```
Length：也就是 Frame 的长度，默认最大长度是 16KB，如果要发送更大的 Frame，需要显示的设置 max frame size。

Type：Frame 的类型，譬如有 DATA，HEADERS，PRIORITY 等。Flag 和 R：保留位，可以先不管。

Stream Identifier：标识所属的 stream，如果为 0，则表示这个 frame 属于整条连接。

Frame Payload：根据不同 Type 有不同的格式。

## stream特性
一条连接可以包含多个 streams，多个 streams 发送的数据互相不影响。  
Stream 可以被 client 和 server 单方面或者共享使用。  
Stream 可以被任意一段关闭。  
Stream 会确定好发送 frame 的顺序，另一端会按照接受到的顺序来处理。  
Stream 用一个唯一 ID 来标识。  
stream 有优先级，方便对端为不同的请求分配不同的资源。譬如对于一个 Web 站点来说，优先加载重要的资源，而对于一些不那么重要的图片啥的，则使用低的优先级。

## HPACK(头部简化)

HPACK 提供了一个静态和动态的 table，静态 table 定义了通用的 HTTP header fields，譬如 method，path 等。发送请求的时候，只要指定 field 在静态 table 里面的索引，双方就知道要发送的 field 是什么了。

对于动态 table，初始化为空，如果两边交互之后，发现有新的 field，就添加到动态 table 上面，这样后面的请求就可以跟静态 table 一样，只需要带上相关的 index 就可以了。

同时，为了减少数据传输的大小，使用 Huffman 进行编码。这里就不再详细说明 HPACK 和 Huffman 如何编码了。
## FlowControl
HTTP/2 支持流控，如果 sender 端发送数据太快，receiver 端可能因为太忙，或者压力太大，或者只想给特定的 stream 分配资源，receiver 端就可能不想处理这些数据。

特性:
Flow control 是单向的。Receiver 可以选择给 stream 或者整个连接设置 window size。  
Flow control 是基于信任的。Receiver 只是会给 sender 建议它的初始连接和 stream 的 flow control window size。  
Flow control 不可能被禁止掉。当 HTTP/2 连接建立起来之后，client 和 server 会交换 SETTINGS frames，用来设置 flow control window size。  
Flow control 是 hop-by-hop，并不是 end-to-end 的，也就是我们可以用一个中间人来进行 flow control。  