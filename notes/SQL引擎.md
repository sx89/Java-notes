# 星型模型和雪花型模型比较

https://blog.csdn.net/nisjlvhudy/article/details/7889422



# HBase 上的 SQL 引擎，Kylin 和 Phoenix 的不同

https://www.cnblogs.com/bonelee/p/12442904.html

1）Kylin 和 Phoenix 虽然同为 Hadoop/HBase 上的 SQL 引擎，两者的定位不同，一个是 OLAP，另一个是 OLTP，服务于不同的场景；

2）Phoenix 更多的是适用于以往关系型数据库的相关操作，当查询语句是点查找和小范围扫描时，Phoenix 可以比较好地满足，而它不太适合大量 scan 类型的 OLAP 查询，或查询的模式较为灵活的场景；

3）Kylin 是一个只读型的分析引擎，不适合细粒度修改数据，但适合做海量数据的交互式在线分析，通常跟数据仓库以及 BI 工具结合使用，目标用户为业务分析人员。

# OLAP、OLTP的介绍和比较

https://blog.csdn.net/zhangzheng0413/article/details/8271322

数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）。OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 





# MySQL存储引擎



## MySQL逻辑架构

MySQL是一个开放源代码的关系数据库管理系统。原开发者为瑞典的MySQL AB公司，最早是在2001年MySQL3.23进入到管理员的视野并在之后获得广泛的应用。

当MySQL启动（MySQL服务器就是一个进程），等待客户端连接，每一个客户端连接请求，服务器都会新建一个线程处理（如果是线程池的话，则是分配一个空的线程），每个线程独立，拥有各自的内存处理空间。

MySQL总体上可分为Server层和存储引擎层。

Server层包括连接器、查询器、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。

<img src="pictures/SQL%E5%BC%95%E6%93%8E/image-20200504201905441.png" alt="image-20200504201905441" style="zoom:50%;" />

MySQL 整体上可以分为 Server 层和存储引擎层两部分。详细的分层如下：

1.客户端层： 连接处理、授权认证、安全等功能均在这一层处理。包含本地sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

2.核心服务层：查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)等。该层架构主要完成核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作。如果是select语句，服务器还会查询内部的缓存。如果缓存空间足够大，这样在解决大量读操作的环境中能够很好的提升系统的性能。

3.存储引擎层：存储过程、触发器、视图等。存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。

4.数据存储层，主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互。

最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。

## MySQL查询过程

我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：**很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。**比如向左解析，向右解析；比如连接池。

当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？

<img src="pictures/SQL%E5%BC%95%E6%93%8E/image-20200504202331137.png" alt="image-20200504202331137" style="zoom:50%;" />



## 客户端/服务端通信协议

MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。

客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。

与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。

## SQL缓存

在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。

MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。

如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。

既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：

1. 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存
2. 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗

基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：

1. 用多个小表代替一个大表，注意不要过度设计
2. 批量插入代替循环单条插入
3. 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适
4. 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存

最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。

当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等



## 语法解析和预处理



<img src="pictures/SQL%E5%BC%95%E6%93%8E/image-20200504215918372.png" alt="image-20200504215918372" style="zoom:50%;" />



MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。

这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等。

**SQL执行计划流程图**

<img src="pictures/SQL%E5%BC%95%E6%93%8E/image-20200504220009336.png" alt="image-20200504220009336" style="zoom:50%;" />

## 查询优化

<img src="pictures/SQL%E5%BC%95%E6%93%8E/image-20200504220032140.png" alt="image-20200504220032140" style="zoom:50%;" />

经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。

MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。

## 事务

- 共享锁与排它锁 
    -  读 
        - 共享锁
    -  写 
        - 排它锁
-  隔离怎么实现？ 
    - 锁
    -  InnoDB存在两种锁 
        - 共享锁（S锁） ：（插入/修改/删除）资源获取S锁之后，能加S锁，不能加X锁
        - 排它锁（X锁） ： 资源加上X锁之后，不能加S锁，也不能加X锁

## 数据库事务实现原理剖析

### 事务的实现原理

-  事务的执行过程 
    - 系统会为每个事务开辟一个私有工作区
    - 事务读操作将从磁盘中拷贝数据项到工作区中,在执行写操作前所有的更新都作用于工作区中的拷贝.
    - 事务的写操作将把数据输出到内存的缓冲区中,再由缓冲区管理器将数据写入到磁盘。
-  分特性 
    -  原子性 
        -  原子性是事务的基本特性，保证了事务中的操作是不可拆分的整体，那么原子性是如何实现的呢？事务的原子性表现的两个方面： 
            -  事务提交成功时，那么事务中的操作总会完成 
                - 事务提交成功保证事务中的操作都会完成。1、是正确执行完事务，没有出现任何问题；2、是事务提交成功但是出异常，数据库恢复之后，提交完成的事务会保证数据库完成该事物的操作。对于第一种正常情况不予讨论，因为不存在 异常情况，那么第2种实际上是和上文说的持久性是相关联的，而这个是基于重做日志（redo log）来保证提交完成的事务在异常情况下保证数据操作能够进行：
            -  事务提交失败，那么事务中的操作都失败 
                - 事务提交失败，那么事务中的操作都失败，这个是通过数据库的撤销操作日志来保证的，也称之为undo log。
        - 通过redo log 来实现
    -  一致性 
        - 通过undo log 来实现
    -  隔离性 
        - 锁
        -  MVCC 多版本并发控制 
            -  MVCC 是什么？ 
                - 人们一般把基于锁的并发控制机制称成为悲观机制，而把MVCC机制称为乐观机制。这是因为锁机制是一种预防性的，读会阻塞写，写也会阻塞读，当锁定粒度较大，时间较长时并发性能就不会太好；而MVCC是一种后验性的，读不阻塞写，写也不阻塞读，等到提交的时候才检验是否有冲突，由于没有锁，所以读写不会相互阻塞，从而大大提升了并发性能。
                -  通过增加系统版本号，每次事务操作，会比较系统版本号 
                - InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一。在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。
            - 基于CAS（Compare-and-swap）
            - 有条件更新（Conditional Update）
-  Undo原理 与 Redo原理 
    -  Undo原理：（备份旧数据） 
        - 在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为Undo Log）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。
    -  Redo原理：（保存最新数据） 
        - 和Undo Log相反，Redo Log记录的是新数据的备份。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是Redo Log已经持久化。系统可以根据Redo Log的内容，将所有数据恢复到最新的状态。



# 分布式sql引擎原理分析



不管是传统数据库或者基于sql的分布式大数据分析工具，基本原理都是把一个sql转换成sql语法树(AST)，通过对语法树的分析转换成执行计划。**传统数据库会根据执行计划通过执行引擎并返回结果；而大数据sql分析工具，由于针对更大数据量而生，为了更好的扩展性、容错性和高可用，会把执行计划分成逻辑执行计划和物理执行计划，并且根据查询sql的特点切分逻辑计划，这样可以把分块的逻辑计划分配到更具扩展性的并行节点，最后根据逻辑执行计划转成物理执行计划进行查询。**

   本文档以当前流行的分布式大数据查询引擎Presto为切入点，分析一个query语句怎么生成为一个分段的逻辑计划。下图是当前流行大数据sql查询引擎(包括hive/sparksql)，生成逻辑计划的过程：

<img src="pictures/SQL%E5%BC%95%E6%93%8E/image-20200505084221751.png" alt="image-20200505084221751" style="zoom:50%;" />

从图中可以看到，当用户通过presto-cli或者jdbc接口提交了一个query请求到Presto的Coordinator节点，首先会被解析器(Parser)转换成一颗sql语法树，这一步只是通过预定的分词规则把一个词组结构(List)转换成了树结构(Tree)，但是这时候不能理解这颗树代表的含义是什么？所以被称作Unresovled AST，这时候需要再通过分析器(Analyzer)来绑定元数据(metaData)。

​     数据结构和编译原理知识知道，Tree这种结构或者说AST这种结构有一个非常重要的特性就是可以等价变换，这个特性在其做分析元数据及优化查询时非常有用。在通过等价变换成Unresovled AST后，称为UnOptimized AST这时候通过这颗AST可以基本分析出提交了一个样的语句，其中关联了什么表，这些表的基本结构是怎样的，其中又使用了什么函数等等。绑定元数据的AST后还需针对具体的操作(主要是join)节点进行优化，使用优化器(Optimizer)进行优化转换成Optimized AST。最后把优化后AST进行逻辑分段，变成可供分布式分析的分段逻辑执行计划。

​     下面以Presto为例具体实际分析怎么实施。

## Parser

Parser的过程实际是一个把sql语句根据分词规则及语法规则再组装成基本AST的过程。当前大部分都是使用的Antlr4工具。从源码的角度看：

presto-main模块的execution包中SqlQueryManager的createQuery发起了Query操作，

Antlr4工具具体分为lexer和parser，lexer叫做词法分析器，而parser叫做语法分析器。举个小例子，以下面这个定义chars sp =100来说，会先根据定义好的tokens进行分词，再语法分析成AST：

而presto它的lexer是在presto-parser中定义，其中分词器:





























































































































































